import cv2
import numpy as np
import time
import os
from ultralytics import YOLO

# -------------------------------
# ìƒ‰ìƒ íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜
# -------------------------------
def get_color_feature(image):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    hist = cv2.calcHist([hsv], [0, 1], None, [50, 60], [0, 180, 0, 256])
    cv2.normalize(hist, hist)
    return hist

# -------------------------------
# ë“±ë¡ ë‹¨ê³„ (ì•/ë’¤/ì¢Œ/ìš° ìë™ ì´¬ì˜)
# -------------------------------
def register_person(model, cap):
    directions = ["Front", "Back", "Left", "Right"]
    base_features = []

    for direction in directions:
        print(f"ğŸ“¸ {direction} ì´¬ì˜ ì¤€ë¹„... 5ì´ˆ ëŒ€ê¸°")

        # 5ì´ˆ ë™ì•ˆ ì‹¤ì‹œê°„ í™”ë©´ í‘œì‹œ
        start_time = time.time()
        while time.time() - start_time < 5:
            ret, frame = cap.read()
            if not ret:
                continue
            cv2.putText(frame, f"{direction}", (30, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
            cv2.imshow("ai-smart-fan", frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                return []

        # 5ì´ˆ í›„ ì´¬ì˜
        ret, frame = cap.read()
        if not ret:
            continue

        results = model.predict(source=frame, conf=0.5, verbose=False)
        if len(results[0].boxes) == 0:
            print("âŒ ì‚¬ëŒì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            continue

        # ì²« ë²ˆì§¸ ì‚¬ëŒ ROI ì¶”ì¶œ
        x1, y1, x2, y2 = map(int, results[0].boxes[0].xyxy[0])
        roi = frame[y1:y2, x1:x2]

        # íŠ¹ì§• ì¶”ì¶œ
        feature = get_color_feature(roi)
        base_features.append(feature)

        # ì´¬ì˜ ê²°ê³¼ 1ì´ˆ ë³´ì—¬ì£¼ê¸°
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(frame, f"{direction} Registered", (x1, y1-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)
        cv2.putText(frame, "Person", (x1, y2+30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)
        cv2.imshow("ai-smart-fan", frame)
        cv2.waitKey(1000)

    # ai í´ë” ì•ˆì— ì €ì¥
    os.makedirs("ai", exist_ok=True)
    np.save("ai/base_features.npy", base_features)
    print("âœ… ë“±ë¡ ì™„ë£Œ: ë„¤ ë°©í–¥ íŠ¹ì§• ì €ì¥ë¨")
    return base_features

# -------------------------------
# ì¶”ì  ë‹¨ê³„ (ë“±ë¡ëœ ì‚¬ëŒë§Œ í‘œì‹œ + 10ì´ˆë§ˆë‹¤ ë™ì  íŠ¹ì§• ì—…ë°ì´íŠ¸)
# -------------------------------
def track_registered_person(model, cap, base_features):
    print("ğŸ“· ë“±ë¡ëœ ì‚¬ëŒë§Œ íŠ¸ë˜í‚¹ ì‹œì‘... (ì¢…ë£Œ: Q í‚¤)")

    dynamic_features = []  # ë³„ë„ ê´€ë¦¬ (ìµœëŒ€ 20ì¥)
    last_capture_time = time.time()
    last_print_time = time.time()  # ì¤‘ì•™ ì¢Œí‘œ ì¶œë ¥ìš©

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        h, w = frame.shape[:2]  # í”„ë ˆì„ í¬ê¸°
        center_x, center_y = w // 2, h // 2  # í™”ë©´ ì¤‘ì•™

        results = model.predict(source=frame, conf=0.5, verbose=False)

        best_sim = 0
        best_box = None
        best_roi = None

        for box in results[0].boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            roi = frame[y1:y2, x1:x2]
            current_feature = get_color_feature(roi)

            # base_features + dynamic_features ëª¨ë‘ ë¹„êµ
            all_features = base_features + dynamic_features
            sims = [cv2.compareHist(f, current_feature, cv2.HISTCMP_CORREL) for f in all_features]
            max_sim = max(sims) if sims else 0  # í‰ê·  ëŒ€ì‹  ìµœëŒ€ê°’ ì‚¬ìš©

            if max_sim > best_sim:
                best_sim = max_sim
                best_box = (x1, y1, x2, y2)
                best_roi = roi

        # ë“±ë¡ëœ ì‚¬ëŒë§Œ í‘œì‹œ
        if best_box and best_sim > 0.7:
            x1, y1, x2, y2 = best_box
            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2  # ë°”ìš´ë”©ë°•ìŠ¤ ì¤‘ì•™
            rel_x, rel_y = cx - center_x, cy - center_y  # í™”ë©´ ì¤‘ì•™ ê¸°ì¤€ ì¢Œí‘œ

            cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)
            cv2.putText(frame, "Registered Person", (x1, y1-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)
            cv2.putText(frame, "Person", (x1, y2+30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)

            # 1ì´ˆë§ˆë‹¤ ì¤‘ì•™ ì¢Œí‘œ ì¶œë ¥ (í™”ë©´ ì¤‘ì•™ ê¸°ì¤€)
            if time.time() - last_print_time > 1:
                print(f"ğŸ“ ì¤‘ì•™ ê¸°ì¤€ ì¢Œí‘œ: ({rel_x}, {rel_y})")
                last_print_time = time.time()

            # 10ì´ˆë§ˆë‹¤ ìƒˆë¡œìš´ íŠ¹ì§• ì¶”ê°€
            if time.time() - last_capture_time > 10 and best_sim > 0.8:  # ê²€ì¦ ì¡°ê±´ ê°•í™”
                new_feature = get_color_feature(best_roi)
                dynamic_features.append(new_feature)
                if len(dynamic_features) > 20:
                    dynamic_features.pop(0)  # ì˜¤ë˜ëœ íŠ¹ì§• ì‚­ì œ
                last_capture_time = time.time()
                print(f"ğŸ“¸ ìƒˆë¡œìš´ íŠ¹ì§• ì¶”ê°€ (ë™ì  {len(dynamic_features)}ì¥ ìœ ì§€ ì¤‘)")

        cv2.imshow("ai-smart-fan", frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

# -------------------------------
# ë©”ì¸ ì‹¤í–‰
# -------------------------------
if __name__ == "__main__":
    model = YOLO("ai/human_detect.pt")
    cap = cv2.VideoCapture(0)

    # ë“±ë¡ ë‹¨ê³„ ì‹¤í–‰
    base_features = register_person(model, cap)

    # ì¶”ì  ë‹¨ê³„ ì‹¤í–‰
    if base_features:
        track_registered_person(model, cap, base_features)